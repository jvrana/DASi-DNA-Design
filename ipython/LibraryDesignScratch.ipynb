{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dasi import LibraryDesign, Design\n",
    "from pyblast.utils import make_linear, make_circular, load_fasta_glob, load_genbank_glob\n",
    "import warnings\n",
    "from Bio import BiopythonParserWarning\n",
    "from matplotlib import MatplotlibDeprecationWarning\n",
    "from dasi.constants import Constants\n",
    "\n",
    "warnings.simplefilter(\"ignore\", BiopythonParserWarning)\n",
    "warnings.simplefilter('ignore', MatplotlibDeprecationWarning)\n",
    "\n",
    "templates = make_circular(load_genbank_glob(\"../tests/data/test_data/genbank/templates/*.gb\"))\n",
    "registry = make_circular(load_genbank_glob(\"../tests/data/test_data/genbank/benchling_registry/*.gb\"))\n",
    "primers = make_linear(load_fasta_glob('../tests/data/test_data/primers/primers.fasta'))\n",
    "queries = make_circular(load_genbank_glob('../tests/data/test_data/genbank/designs/*.gb'))\n",
    "\n",
    "assert templates\n",
    "assert registry\n",
    "assert primers\n",
    "assert queries\n",
    "\n",
    "design = Design(span_cost)\n",
    "design.add_templates(registry)\n",
    "design.add_primers(primers)\n",
    "design.add_queries(queries)\n",
    "design.add_fragments([])\n",
    "\n",
    "# blast = design.blast_factory('queries', 'queries')\n",
    "# blast.quick_blastn()\n",
    "# results = blast.get_perfect()\n",
    "# results = [r for r in results if r['subject']['origin_key'] != r['query']['origin_key']]\n",
    "\n",
    "# design.container_factory.seqdb.update(blast.seq_db.records)\n",
    "# design.container_factory.load_blast_json(results, Constants.SHARED_FRAGMENT)\n",
    "design.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "less than 25% GC content\n",
    "higher than 75% GC content\n",
    "homopolymeric runs of 10 or more A/Ts\n",
    "homopolymeric runs of 6 or more G/Cs\n",
    "repeats greater than 14bp\n",
    "hairpins\n",
    "\n",
    "GC scew?\n",
    "windowed scew?\n",
    "\"\"\"\n",
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "def random_seq(length, bases=None):\n",
    "    if bases is None:\n",
    "      bases = \"AGTC\"\n",
    "\n",
    "    seq = \"\"\n",
    "    for _ in range(length):\n",
    "        i = random.randint(0, len(bases)-1)\n",
    "        seq += bases[i]\n",
    "    return seq\n",
    "\n",
    "HOMOPOLYMERIC_AT = 6\n",
    "HOMOPOLYMERIC_GC = 10\n",
    "REPEAT_MAX_LENGTH = 14\n",
    "PARTITION_OVERLAP = 25\n",
    "\n",
    "def get_AT_complexity(seq):\n",
    "  complexities = []\n",
    "  for match in re.findall(\"[AT]+\", seq, re.IGNORECASE):\n",
    "    if len(match) > HOMOPOLYMERIC_AT:\n",
    "      complexities.append(len(match) - HOMOPOLYMERIC_AT + 1)\n",
    "  if complexities:\n",
    "    return max(complexities)\n",
    "  return 0\n",
    "\n",
    "def get_GC_complexity(seq):\n",
    "  complexities = []\n",
    "  for match in re.findall(\"[GC]+\", seq, re.IGNORECASE):\n",
    "    if len(match) > HOMOPOLYMERIC_GC:\n",
    "      complexities.append(len(match) - HOMOPOLYMERIC_GC + 1)\n",
    "  if complexities:\n",
    "    return max(complexities)\n",
    "  return 0\n",
    "\n",
    "def get_GC_content(seq):\n",
    "  s = seq.upper()\n",
    "  return (s.count('G') + s.count('C')) / len(s)\n",
    "\n",
    "def get_GC_content_complexity(seq):\n",
    "  gc = get_GC_content(seq)\n",
    "  return abs(gc * 100. - 50) * 17 / 25.\n",
    "\n",
    "def iter_kmers(seq, length):\n",
    "  for i in range(0, len(seq)-length):\n",
    "    yield (i, seq[i:i+length])\n",
    "\n",
    "def count_kmers(seq, length):\n",
    "  kmers = {}\n",
    "  for kmer in iter_kmers(seq, length):\n",
    "    kmers.setdefault(kmer[1], list())\n",
    "    kmers[kmer[1]].append(kmer[0])\n",
    "  return kmers\n",
    "\n",
    "def get_repeat_complexity(seq, length):\n",
    "  repeats = {\n",
    "      \n",
    "  }\n",
    "  for kmer, positions in count_kmers(seq, length).items():\n",
    "    if len(positions) > 1:\n",
    "      these_kmers = [kmer] * len(positions)\n",
    "      kmer1 = kmer2 = kmer\n",
    "      l = len(kmer)\n",
    "      while kmer1 == kmer2:\n",
    "        l += 1\n",
    "        kmer1 = seq[positions[0]:positions[0]+l]\n",
    "        kmer2 = seq[positions[1]:positions[1]+l]\n",
    "      passes = True\n",
    "      if len(kmer1) >= length:\n",
    "        for k in repeats:\n",
    "          if kmer1 in k:\n",
    "            passes = False\n",
    "            break\n",
    "        if passes:\n",
    "          repeats[kmer1] = (len(kmer1) - length) * 2\n",
    "  return repeats\n",
    "\n",
    "def complexity(seq):\n",
    "  complexity_info = {}\n",
    "  complexity_info['Homopolymeric AT'] = get_AT_complexity(seq)\n",
    "  complexity_info['Homopolymeric GC'] = get_GC_complexity(seq)\n",
    "  complexity_info['High GC Content'] = get_GC_content_complexity(seq)\n",
    "  complexity_info['Repeats'] = get_repeat_complexity(seq, REPEAT_MAX_LENGTH)\n",
    "  return complexity_info\n",
    "\n",
    "def complexity_score(seq):\n",
    "  data = complexity(seq)\n",
    "  total = 0\n",
    "  for k, v in data.items():\n",
    "    if isinstance(v, int) or isinstance(v, float):\n",
    "      total += v\n",
    "    else:\n",
    "      for _v in v.values():\n",
    "        total += _v\n",
    "  return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "import bisect\n",
    "\n",
    "def group_by(a, key, valfunc=None):\n",
    "  groups = {}\n",
    "  for x in tee(a)[0]:\n",
    "    k = key(x)\n",
    "    groups.setdefault(k, list())\n",
    "    if valfunc:\n",
    "      x = valfunc(x)\n",
    "    groups[k].append(x)\n",
    "  return groups\n",
    "seq = random_seq(1000)\n",
    "\n",
    "matches = []\n",
    "for m in re.finditer('[AT]{6,}', seq):\n",
    "  matches.append((m.start(), m.end(), m.group()))\n",
    "\n",
    "a = sorted(matches, key=lambda m: m[0])\n",
    "b = sorted(matches, key=lambda m: m[1])\n",
    "\n",
    "bisect.bisect_left(a, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceStats(object):\n",
    "    \n",
    "    def __init__(self, seq):\n",
    "        self.seq = seq\n",
    "    \n",
    "        self.at_matches = []\n",
    "        a_keys = [_a[0] for _a in a]\n",
    "        for m in re.finditer('[AT]{6,}', seq):\n",
    "            matches.append((m.start(), m.end(), m.group()))\n",
    "        self.at_a = sorted(matches, key=lambda m: m[0])\n",
    "        self.at_b = sorted(matches, key=lambda m: m[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8193/8193 [00:00<00:00, 137478.28it/s]\n",
      "100%|██████████| 6918/6918 [00:00<00:00, 170494.95it/s]\n",
      "100%|██████████| 7441/7441 [00:00<00:00, 197044.11it/s]\n",
      "100%|██████████| 3404/3404 [00:00<00:00, 115659.95it/s]\n",
      "100%|██████████| 7057/7057 [00:00<00:00, 194649.64it/s]\n",
      "100%|██████████| 3859/3859 [00:00<00:00, 143020.91it/s]\n",
      "100%|██████████| 6214/6214 [00:00<00:00, 221407.32it/s]\n",
      "100%|██████████| 8871/8871 [00:00<00:00, 208351.79it/s]\n",
      "100%|██████████| 3887/3887 [00:00<00:00, 136553.51it/s]\n",
      "100%|██████████| 8130/8130 [00:00<00:00, 203102.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13d474a90>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import bisect\n",
    "\n",
    "nseqs = 0\n",
    "scores = []\n",
    "for qk, g in design.graphs.items():\n",
    "    seq = str(design.seqdb[qk].seq)\n",
    "    \n",
    "    matches = []\n",
    "    for m in re.finditer('[AT]{6,}', seq):\n",
    "        matches.append((m.start(), m.end(), m.group()))\n",
    "\n",
    "    a = sorted(matches, key=lambda m: m[0])\n",
    "    b = sorted(matches, key=lambda m: m[1])\n",
    "    \n",
    "    a_keys = [_a[0] for _a in a]\n",
    "    b_keys = [_b[1] for _b in b]\n",
    "    print(a_keys)\n",
    "    print(b)\n",
    "    for n1, n2, edata in tqdm(g.edges(data=True), total=g.number_of_edges()):\n",
    "        if n1.type == 'B' and n2.type == 'A':\n",
    "            nseqs += 1\n",
    "            seqslice = seq[n1.index:n2.index]\n",
    "            if len(seqslice):\n",
    "                np.unique(seqslice, return_counts=True)\n",
    "                i = bisect.bisect_left(keys, n1.index)\n",
    "                \n",
    "print(len(scores))\n",
    "\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssemblyNode(index=326, expandable=True, type='B', overhang=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6832"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print(len(scores))\n",
    "len([s for s in scores if s > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AssemblyNode(index=0, expandable=True, type='A', overhang=True),\n",
       " AssemblyNode(index=4779, expandable=True, type='B', overhang=True))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(g.edges())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dasi.models import AlignmentContainer\n",
    "from dasi.utils import sort_with_keys\n",
    "from dasi.utils import Region\n",
    "\n",
    "def overlapping_groups(group_list_a, group_list_b):\n",
    "    group_sort, group_keys = sort_with_keys(\n",
    "            group_list_b, key=lambda x: x.query_region.a\n",
    "        )\n",
    "    tuples = []\n",
    "    for group_a in group_list_a:\n",
    "        alignments = []\n",
    "        overlapping = AlignmentContainer.filter_alignments_by_span(\n",
    "                group_sort,\n",
    "                group_a.query_region,\n",
    "                key=lambda p: p.query_region.a,\n",
    "                end_inclusive=False,\n",
    "            )\n",
    "        if group_a in overlapping:\n",
    "            overlapping.remove(group_a)\n",
    "        tuples.append((group_a, overlapping))\n",
    "    return tuples\n",
    "\n",
    "\n",
    "all_groups = []\n",
    "for container in design.container_factory.containers().values():\n",
    "    all_groups += container.get_groups_by_types(Constants.SHARED_FRAGMENT)\n",
    "    \n",
    "grouped_by_qk = {}\n",
    "for g in all_groups:\n",
    "    grouped_by_qk.setdefault(g.query_key, list())\n",
    "    grouped_by_qk[g.query_key].append(g)\n",
    "\n",
    "for qk, groups in list(grouped_by_qk.items())[:]:\n",
    "    overlapping = overlapping_groups(groups, groups)\n",
    "    starts = []\n",
    "    ends = []\n",
    "    for g, glist in overlapping:\n",
    "        starts.append(g.query_region.start)\n",
    "        ends.append(g.query_region.end)\n",
    "        for _g in glist:\n",
    "            starts.append(_g.query_region.start)\n",
    "            ends.append(_g.query_region.end)\n",
    "#     overlapping = overlapping_groups(groups, groups)\n",
    "#     print(len(overlapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def to_undirected(graph):\n",
    "    \"\"\".to_undirected is implemented in networkx out of the box, however, it\n",
    "    suffers from occational infinite recursion errors during the deepcopy phase\n",
    "    of the method (unknown as to why).\"\"\"\n",
    "    undirected = nx.Graph()\n",
    "    copied = deepcopy(graph)\n",
    "    for n in copied.nodes:\n",
    "        ndata = copied.nodes[n]\n",
    "        undirected.add_node(n, **ndata)\n",
    "    for n1, n2 in copied.edges:\n",
    "        edata = copied.edges[n1, n2]\n",
    "        undirected.add_edge(n1, n2, **edata)\n",
    "    return undirected\n",
    "\n",
    "def get_subgraphs(graph):\n",
    "    \"\"\"Get independent subgraphs.\"\"\"\n",
    "    node_list = list(graph.nodes)\n",
    "    subgraphs = []\n",
    "    while len(node_list) > 0:\n",
    "        node = node_list[-1]\n",
    "        subgraph = nx.bfs_tree(to_undirected(graph), node)\n",
    "        for n in subgraph.nodes:\n",
    "            node_list.remove(n)\n",
    "        subgraphs.append(graph.subgraph(subgraph.nodes))\n",
    "    return subgraphs\n",
    "\n",
    "\n",
    "interaction_graph = nx.Graph()\n",
    "\n",
    "for g in all_groups:\n",
    "    for a in g.alignments:\n",
    "        n1 = (a.query_key, a.query_region.a, a.query_region.b)\n",
    "        n2 = (a.subject_key, a.subject_region.a, a.subject_region.b)\n",
    "        interaction_graph.add_edge(n1, n2, alignment=a)\n",
    "graphs = sorted(get_subgraphs(interaction_graph), key=lambda x: x.number_of_nodes())\n",
    "\n",
    "graph = graphs[-2]\n",
    "\n",
    "def has_repeats(g):\n",
    "    \"\"\"Check if the interaction graph has a repeated DNA sequence\"\"\"\n",
    "    grouped_by_key = {}\n",
    "    for n in g.nodes:\n",
    "        grouped_by_key.setdefault(n[0], list())\n",
    "        grouped_by_key[n[0]].append((n[1], n[2]))\n",
    "    for k, v in grouped_by_key.items():\n",
    "        if len(v) > 1:\n",
    "            print(grouped_by_key)\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "nx.draw(graph, node_size=25)\n",
    "\n",
    "# clusters have \n",
    "clusters = []\n",
    "\n",
    "for g in graphs:\n",
    "    if not has_repeats(g):\n",
    "        alignments = []\n",
    "        for n1, n2, edata in g.edges(data=True):\n",
    "            alignments.append(edata['alignment'])\n",
    "        clusters.append(alignments)\n",
    "\n",
    "qk_to_cluster_indices = {}\n",
    "for i, c in enumerate(clusters):\n",
    "    for alignment in c:\n",
    "        qk_to_cluster_indices.setdefault(alignment.query_key, (alignment, list()))\n",
    "        qk_to_cluster_indices[alignment.query_key][1].append(i)\n",
    "\n",
    "for qk, container in design.container_factory.containers().items():\n",
    "    alignment, cluster = qk_to_cluster_indices[qk]\n",
    "#     graph = design.graphs[qk]\n",
    "#     container.filter_alignments_by_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design.graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design.seqdb['2bf55dde-2d75-4e56-b6ce-eb09479d461e'][734:811]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = dict()\n",
    "for g in all_groups:\n",
    "    keys = [g.query_key] + g.subject_keys\n",
    "    keys.sort()\n",
    "    gkey = tuple(keys)\n",
    "    all_keys.setdefault(gkey, list())\n",
    "    all_keys[gkey].append(g)\n",
    "    \n",
    "print(len(all_groups))\n",
    "print(len(all_keys))\n",
    "\n",
    "all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "\n",
    "blast = design.blast_factory('queries', 'queries')\n",
    "\n",
    "blast.quick_blastn()\n",
    "results = blast.get_perfect()\n",
    "results = [r for r in results if r['subject']['origin_key'] != r['query']['origin_key']]\n",
    "\n",
    "g = nx.MultiGraph()\n",
    "\n",
    "edges = []\n",
    "for r in results:\n",
    "    sk = r['subject']['origin_key']\n",
    "    qk = r['query']['origin_key']\n",
    "    k1 = (qk, (r['query']['start'], r['query']['end']))\n",
    "    k2 = (sk, (r['subject']['start'], r['subject']['end']))\n",
    "    keys = sorted([k1, k2])\n",
    "    edges.append(keys)\n",
    "    \n",
    "for n1, n2 in edges:\n",
    "    g.add_edge(n1[0], n2[0])\n",
    "    \n",
    "nx.draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
